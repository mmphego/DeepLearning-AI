<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Week 1</title><style>
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	text-indent: -1.7em;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, YuMincho, "Yu Mincho", "Hiragino Mincho ProN", "Hiragino Mincho Pro", "Songti TC", "Songti SC", "SimSun", "Nanum Myeongjo", NanumMyeongjo, Batang, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC', 'Noto Sans CJK KR'; }

.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Consolas, "Liberation Mono", Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC', 'Noto Sans Mono CJK KR'; }

.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, YuMincho, "Yu Mincho", "Hiragino Mincho ProN", "Hiragino Mincho Pro", "Songti TC", "Songti SC", "SimSun", "Nanum Myeongjo", NanumMyeongjo, Batang, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC', 'Noto Sans CJK KR'; }

.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC', 'Noto Sans Mono CJK KR'; }

.highlight-default {
}
.highlight-gray {
	color: rgb(155,154,151);
}
.highlight-brown {
	color: rgb(100,71,58);
}
.highlight-orange {
	color: rgb(217,115,13);
}
.highlight-yellow {
	color: rgb(223,171,1);
}
.highlight-teal {
	color: rgb(15,123,108);
}
.highlight-blue {
	color: rgb(11,110,153);
}
.highlight-purple {
	color: rgb(105,64,165);
}
.highlight-pink {
	color: rgb(173,26,114);
}
.highlight-red {
	color: rgb(224,62,62);
}
.highlight-gray_background {
	background: rgb(235,236,237);
}
.highlight-brown_background {
	background: rgb(233,229,227);
}
.highlight-orange_background {
	background: rgb(250,235,221);
}
.highlight-yellow_background {
	background: rgb(251,243,219);
}
.highlight-teal_background {
	background: rgb(221,237,234);
}
.highlight-blue_background {
	background: rgb(221,235,241);
}
.highlight-purple_background {
	background: rgb(234,228,242);
}
.highlight-pink_background {
	background: rgb(244,223,235);
}
.highlight-red_background {
	background: rgb(251,228,228);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(55, 53, 47, 0.6);
	fill: rgba(55, 53, 47, 0.6);
}
.block-color-brown {
	color: rgb(100,71,58);
	fill: rgb(100,71,58);
}
.block-color-orange {
	color: rgb(217,115,13);
	fill: rgb(217,115,13);
}
.block-color-yellow {
	color: rgb(223,171,1);
	fill: rgb(223,171,1);
}
.block-color-teal {
	color: rgb(15,123,108);
	fill: rgb(15,123,108);
}
.block-color-blue {
	color: rgb(11,110,153);
	fill: rgb(11,110,153);
}
.block-color-purple {
	color: rgb(105,64,165);
	fill: rgb(105,64,165);
}
.block-color-pink {
	color: rgb(173,26,114);
	fill: rgb(173,26,114);
}
.block-color-red {
	color: rgb(224,62,62);
	fill: rgb(224,62,62);
}
.block-color-gray_background {
	background: rgb(235,236,237);
}
.block-color-brown_background {
	background: rgb(233,229,227);
}
.block-color-orange_background {
	background: rgb(250,235,221);
}
.block-color-yellow_background {
	background: rgb(251,243,219);
}
.block-color-teal_background {
	background: rgb(221,237,234);
}
.block-color-blue_background {
	background: rgb(221,235,241);
}
.block-color-purple_background {
	background: rgb(234,228,242);
}
.block-color-pink_background {
	background: rgb(244,223,235);
}
.block-color-red_background {
	background: rgb(251,228,228);
}
.select-value-color-default { background-color: rgba(206,205,202,0.5); }
.select-value-color-gray { background-color: rgba(155,154,151, 0.4); }
.select-value-color-brown { background-color: rgba(140,46,0,0.2); }
.select-value-color-orange { background-color: rgba(245,93,0,0.2); }
.select-value-color-yellow { background-color: rgba(233,168,0,0.2); }
.select-value-color-green { background-color: rgba(0,135,107,0.2); }
.select-value-color-blue { background-color: rgba(0,120,223,0.2); }
.select-value-color-purple { background-color: rgba(103,36,222,0.2); }
.select-value-color-pink { background-color: rgba(221,0,129,0.2); }
.select-value-color-red { background-color: rgba(255,0,26,0.2); }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="d6239cbc-e5d8-4a09-8095-562a3f8340ab" class="page sans"><header><h1 class="page-title">Week 1</h1><table class="properties"><tbody><tr class="property-row property-row-select"><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.4);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesSelect"><path d="M7,13 C10.31348,13 13,10.31371 13,7 C13,3.68629 10.31348,1 7,1 C3.68652,1 1,3.68629 1,7 C1,10.31371 3.68652,13 7,13 Z M3.75098,5.32278 C3.64893,5.19142 3.74268,5 3.90869,5 L10.09131,5 C10.25732,5 10.35107,5.19142 10.24902,5.32278 L7.15771,9.29703 C7.07764,9.39998 6.92236,9.39998 6.84229,9.29703 L3.75098,5.32278 Z"></path></svg></span>Class</th><td><span class="selected-value select-value-color-brown">C4W1</span></td></tr><tr class="property-row property-row-date"><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.4);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesDate"><path d="M10.8889,5.5 L3.11111,5.5 L3.11111,7.05556 L10.8889,7.05556 L10.8889,5.5 Z M12.4444,1.05556 L11.6667,1.05556 L11.6667,0 L10.1111,0 L10.1111,1.05556 L3.88889,1.05556 L3.88889,0 L2.33333,0 L2.33333,1.05556 L1.55556,1.05556 C0.692222,1.05556 0.00777777,1.75556 0.00777777,2.61111 L0,12.5 C0,13.3556 0.692222,14 1.55556,14 L12.4444,14 C13.3,14 14,13.3556 14,12.5 L14,2.61111 C14,1.75556 13.3,1.05556 12.4444,1.05556 Z M12.4444,12.5 L1.55556,12.5 L1.55556,3.94444 L12.4444,3.94444 L12.4444,12.5 Z M8.55556,8.61111 L3.11111,8.61111 L3.11111,10.1667 L8.55556,10.1667 L8.55556,8.61111 Z"></path></svg></span>Created</th><td><time>@Oct 24, 2020</time></td></tr><tr class="property-row property-row-file"><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.4);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesFile"><path d="M5.94578,14 C4.62416,14 3.38248,13.4963 2.44892,12.585 C1.514641,11.6736 1,10.4639 1,9.17405 C1.00086108,7.88562 1.514641,6.67434 2.44892,5.76378 L7.45612,0.985988 C8.80142,-0.327216 11.1777,-0.332396 12.5354,0.992848 C13.9369,2.36163 13.9369,4.58722 12.5354,5.95418 L8.03046,10.2414 C7.16278,11.0877 5.73682,11.0894 4.86024,10.2345 C3.98394,9.37789 3.98394,7.98769 4.86024,7.1327 L6.60422,5.4317 L7.87576,6.67196 L6.13177,8.37297 C6.01668,8.48539 6.00003,8.61545 6.00003,8.68335 C6.00003,8.75083 6.01668,8.88103 6.13177,8.99429 C6.36197,9.21689 6.53749,9.21689 6.76768,8.99429 L11.2707,4.70622 C11.9645,4.03016 11.9645,2.91757 11.2638,2.23311 C10.5843,1.57007 9.40045,1.57007 8.72077,2.23311 L3.71342,7.0109 C3.12602,7.58406 2.79837,8.35435 2.79837,9.17405 C2.79837,9.99459 3.12602,10.7654 3.72045,11.3446 C4.90947,12.5062 6.98195,12.5062 8.17096,11.3446 L10.41911,9.15165 L11.6906,10.3919 L9.4425,12.585 C8.50808,13.4963 7.2664,14 5.94578,14 Z"></path></svg></span>Materials</th><td></td></tr><tr class="property-row property-row-url"><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.4);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesUrl"><path d="M3.73333,3.86667 L7.46667,3.86667 C8.49613,3.86667 9.33333,4.70387 9.33333,5.73333 C9.33333,6.7628 8.49613,7.6 7.46667,7.6 L6.53333,7.6 C6.01813,7.6 5.6,8.0186 5.6,8.53333 C5.6,9.04807 6.01813,9.46667 6.53333,9.46667 L7.46667,9.46667 C9.5284,9.46667 11.2,7.79507 11.2,5.73333 C11.2,3.6716 9.5284,2 7.46667,2 L3.73333,2 C1.6716,2 0,3.6716 0,5.73333 C0,7.124 0.762067,8.33453 1.88953,8.97713 C1.87553,8.83107 1.86667,8.6836 1.86667,8.53333 C1.86667,7.92013 1.98753,7.33447 2.2036,6.7978 C1.99267,6.4954 1.86667,6.12953 1.86667,5.73333 C1.86667,4.70387 2.70387,3.86667 3.73333,3.86667 Z M12.1095,5.28907 C12.1231,5.4356 12.1333,5.58307 12.1333,5.73333 C12.1333,6.34607 12.0101,6.9294 11.7931,7.46513 C12.0059,7.768 12.1333,8.13573 12.1333,8.53333 C12.1333,9.5628 11.2961,10.4 10.2667,10.4 L6.53333,10.4 C5.50387,10.4 4.66667,9.5628 4.66667,8.53333 C4.66667,7.50387 5.50387,6.66667 6.53333,6.66667 L7.46667,6.66667 C7.98187,6.66667 8.4,6.24807 8.4,5.73333 C8.4,5.2186 7.98187,4.8 7.46667,4.8 L6.53333,4.8 C4.4716,4.8 2.8,6.4716 2.8,8.53333 C2.8,10.59507 4.4716,12.2667 6.53333,12.2667 L10.2667,12.2667 C12.3284,12.2667 14,10.59507 14,8.53333 C14,7.14267 13.2375,5.93167 12.1095,5.28907 Z"></path></svg></span>Property</th><td></td></tr><tr class="property-row property-row-checkbox"><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.4);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesCheckbox"><path d="M0,3 C0,1.34314 1.34326,0 3,0 L11,0 C12.6567,0 14,1.34314 14,3 L14,11 C14,12.6569 12.6567,14 11,14 L3,14 C1.34326,14 0,12.6569 0,11 L0,3 Z M3,1.5 C2.17139,1.5 1.5,2.17157 1.5,3 L1.5,11 C1.5,11.8284 2.17139,12.5 3,12.5 L11,12.5 C11.8286,12.5 12.5,11.8284 12.5,11 L12.5,3 C12.5,2.17157 11.8286,1.5 11,1.5 L3,1.5 Z M2.83252,6.8161 L3.39893,6.27399 L3.57617,6.10425 L3.92334,5.77216 L4.26904,6.10559 L4.44531,6.27582 L5.58398,7.37402 L9.28271,3.81073 L9.45996,3.64008 L9.80664,3.3056 L10.1538,3.63989 L10.3311,3.81067 L10.8936,4.35303 L11.0708,4.52399 L11.4434,4.88379 L11.0708,5.24353 L10.8936,5.41437 L6.1084,10.0291 L5.93115,10.2 L5.58398,10.5344 L5.23682,10.2 L5.05957,10.0292 L2.83057,7.87946 L2.65283,7.70801 L2.27832,7.34674 L2.6543,6.98694 L2.83252,6.8161 Z"></path></svg></span>Reviewed</th><td><div class="checkbox checkbox-on"></div></td></tr><tr class="property-row property-row-select"><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.4);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesSelect"><path d="M7,13 C10.31348,13 13,10.31371 13,7 C13,3.68629 10.31348,1 7,1 C3.68652,1 1,3.68629 1,7 C1,10.31371 3.68652,13 7,13 Z M3.75098,5.32278 C3.64893,5.19142 3.74268,5 3.90869,5 L10.09131,5 C10.25732,5 10.35107,5.19142 10.24902,5.32278 L7.15771,9.29703 C7.07764,9.39998 6.92236,9.39998 6.84229,9.29703 L3.75098,5.32278 Z"></path></svg></span>Type</th><td></td></tr></tbody></table></header><div class="page-body"><h1 id="796cacba-e21c-4784-8ddc-1e375465299c" class="">Convolutional Neural Networks</h1><h2 id="766e2d6b-d263-452d-8262-191c19415282" class="">Computer Vision</h2><p id="080395dc-d2d3-4b27-b7fe-78dcfb93270b" class="">Computer vision is one of the areas that&#x27;s been advancing rapidly thanks to deep learning. Deep learning computer vision is now helping self-driving cars figure out where the other cars and pedestrians around so to avoid them.</p><p id="5ea4b2f6-bd82-4f0f-85fa-6232a9015b0f" class="">
</p><p id="7b5dd606-b4b8-4243-a273-c5a1bb78188b" class="">Some computer vision problems deep learning can help fix:</p><ul id="d7a2d5f2-bee6-4cfc-9a36-40cc0a9243f3" class="bulleted-list"><li>Image classification</li></ul><ul id="b61a13bd-fde8-4b23-a899-9ffc9658cc65" class="bulleted-list"><li>Object detection (multiple bounding boxes)</li></ul><ul id="e731b69e-a741-4f9b-b537-4de8eae6c87e" class="bulleted-list"><li>Neural Style Transfer</li></ul><p id="1763a56c-a3a2-4abc-bd60-a5b6edf9d89b" class="">
</p><p id="220e8070-fd8c-491c-8de1-3f93af65de95" class="">Challenges of computer vision:</p><ul id="ef920686-7bb4-4bbe-85b0-737b3492f4d2" class="bulleted-list"><li>Input data can be large to handle</li></ul><ul id="260c1615-5878-4b98-a201-177f0b583733" class="bulleted-list"><li>Computations resources</li></ul><h2 id="296d9b59-5f43-48e8-9ce9-05010170327b" class="">Edge Detection Example</h2><p id="5efcc5dc-daba-411e-a4ee-c41dad873227" class="">The convolution operation is one of the fundamental building blocks of a convolutional neural network. Using edge detection as the motivating example in image below, we see how the convolution operation works.</p><figure id="044f36fa-0bef-4a78-befb-e50b88b19002" class="image"><a href="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled.png"><img style="width:802px" src="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled.png"/></a></figure><p id="a5c2a4e9-8ead-45f4-b38e-989d42635bf4" class="">Looking at the image about we can create a nn such that:</p><ul id="d2fb869c-399f-4fba-93ba-67b9e7c18498" class="bulleted-list"><li>Layer 1: Detect edges</li></ul><ul id="ded6a76f-7cfd-4041-bbe7-8d5ffe73d3f4" class="bulleted-list"><li>Layer 2: Cause of objects</li></ul><ul id="25d96c7d-b8f9-420d-a723-e36506b7c14f" class="bulleted-list"><li>Later layer: Detect people&#x27;s faces</li></ul><p id="023f7379-3807-443c-8a33-fc25d5973f43" class="">
</p><p id="452bfc3c-a472-41bf-91e9-572d8bddbbbc" class="">Given an image for a computer to figure out what&#x27;s in the image,</p><ul id="77c497f5-3468-488f-8160-11ab35121cc7" class="bulleted-list"><li>The first thing to do would be to detect vertical edges in the image.</li></ul><ul id="1f7e98ad-f605-49d7-bb05-5e76b264f16b" class="bulleted-list"><li>Detect horizontal edges in the image.</li></ul><p id="e46370c9-6209-4c3a-97ff-dc3b4317c43e" class="">
</p><p id="db38db3c-4c32-4cd8-bd42-2975600abd43" class=""><strong>How to detect edges in an image</strong></p><p id="7201334a-6ee6-4870-8119-28a71e9f93cb" class="">
</p><p id="b325b47a-a363-46ad-aea2-9d17071eb1ac" class="">Iteratively:</p><ul id="12482b73-646e-4697-a49b-bc6625749dd5" class="bulleted-list"><li>Construct a 3x3 filter/kernel </li></ul><ul id="28fa0251-7bdf-4079-8b9b-21c8d254df79" class="bulleted-list"><li>Convolve the 6x6 matrics with the kernel<p id="9bdbe75d-d99a-4291-819a-9d4ddfbd6fba" class="">These layers slide (convolve) over the input data, generating a number of &#x27;feature maps&#x27; than can subsequently be used to detect certain patterns in the data. This is achieve by element-wise multiplications between the slice of the input data and the filter/kernel which is currenty hovering over.</p></li></ul><ul id="7414e605-81ea-4c37-9139-3738a4dbcd4c" class="bulleted-list"><li>Output will be a 4x4 matrics.</li></ul><figure id="ea53ae27-eb97-436a-882a-fa0ae571869c" class="image"><a href="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%201.png"><img style="width:800px" src="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%201.png"/></a></figure><p id="d1a20a5b-3371-4902-ab8a-d1c681eaf803" class="">Continue to the next matrics...and so on...</p><figure id="5c4594f2-cfcd-419f-99e9-988ece5bea22" class="image"><a href="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%202.png"><img style="width:797px" src="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%202.png"/></a></figure><p id="53d078ad-88e3-4899-ae4d-13a85dfd9dbd" class="">This turns out to be a<strong> vertical edge detector </strong>in the end.</p><figure id="57b18a31-2d11-49db-bf8a-71dc95f063c6" class="image"><a href="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%203.png"><img style="width:796px" src="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%203.png"/></a></figure><p id="200e5bce-0852-4d29-a7cc-e95254007b1a" class="">Now let&#x27;s look at another example:</p><figure id="270adc34-ca59-4159-be09-59883987b06f" class="image"><a href="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%204.png"><img style="width:795px" src="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%204.png"/></a></figure><p id="23eab290-1414-496e-954e-8a61881163cf" class="">From the image above the detected edge seems to be in the middle and the bright region on the output images tells us that it found a vertical edge in the middle of the image on the left. The reason why it is thick is because we are dealing with very small matrices, if it was a large image the output would be different.</p><p id="2e523dc3-47df-40bf-a592-0f78071ee288" class="">One intuition to take away from the vertical edge detection is that a vertical edge is a 3x3 region since we are using a 3x3 filter where there are bright pixels on the left and dark pixels on the right.</p><h2 id="fc928f3b-78e7-4e91-9eff-9750e5798fd4" class="">More Edge Detection</h2><figure id="589ce1c8-63c0-436d-9b7d-7e85daea8afe" class="image"><a href="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%205.png"><img style="width:725px" src="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%205.png"/></a></figure><p id="923af840-973c-41c9-8c60-588dae8123be" class="">A vertical edge detector according to the filter is a 3x3 region where the pixels are relatively bright on the left part and relatively dark on the right part. Similarly, a horizontal edge detector would be 3x3 region where the pixels are relatively bright on top and dark in the botton row.</p><p id="0a3c30c5-cb75-4b42-b2e4-aaa9d244b1b3" class="">
</p><p id="72397c2b-e3d7-4be6-bc86-dfd8d625075a" class="">In summary, different filters allows us to find vertical and horizontal edges and it turns out that the 3x3 vertical edge detection filter is one possible choice.</p><p id="b3ba2088-0f26-4ad2-b0b1-bad5cc8e5cb4" class="">
</p><p id="7304dca8-aaab-4105-a2b4-7f7315a02b18" class=""><strong>Learning to detect edges with different filters:</strong></p><ul id="bd7124e6-ff20-4040-9cb7-a27f3c25a951" class="bulleted-list"><li>Sobel filter: Advantage is that it puts a little bit more weight to the central row and makes it more robust</li></ul><ul id="ad8f5e35-850c-410a-a11d-b2988cc6ce8b" class="bulleted-list"><li>Scharr filter: This filter has different properties and it&#x27;s mainly used for vertical edge detection.</li></ul><figure id="1bfe887b-252b-4956-85c7-9cd2df6dede5" class="image"><a href="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%206.png"><img style="width:795px" src="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%206.png"/></a></figure><p id="8b4a585b-81f7-426e-afab-5ff5f105dcb6" class="">With the rise of deep learning one of the things we learned is that when you really want to detect edges in a complicated image, you probably do not need to hardcode those numbers instead you can learn them and treat the nine numbers of the matrix as <strong>parameters, </strong>which can be learned using back propagation.</p><h2 id="e7040af7-a4f3-4adb-a33a-e9af49cc6931" class="">Padding</h2><p id="7a762b11-ef5e-4abf-a8bc-750ce9fcede8" class="">In order to build deep neural networks one modification to the basic convolutional operation that you need is to use padding. </p><figure id="57ee3f3f-f065-4073-8b88-924904735228" class="image"><a href="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%207.png"><img style="width:794px" src="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%207.png"/></a></figure><p id="840f9edb-96a8-47be-a41a-09ea9299dd07" class="">In the image above, if you convolve an input image with <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>∗</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">n*n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.46528em;vertical-align:0em;"></span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">n</span></span></span></span></span><span>﻿</span></span> dimensions with a kernel of <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo>∗</mo><mi>f</mi></mrow><annotation encoding="application/x-tex">f*f </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span></span></span></span></span><span>﻿</span></span> dimensions the output dimensions will be <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>−</mo><mi>f</mi><mo>+</mo><mn>1</mn><mo>∗</mo><mi>n</mi><mo>−</mo><mi>f</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">n-f+1 * n-f+1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span></span><span>﻿</span></span></p><p id="30a487dc-3b5f-42d4-92b1-149ea16b257b" class="">
</p><p id="0d5d0b85-e7cc-4ba3-a91b-6c3b6a2e3b4c" class=""><strong>Disadvantages to convolving out input image with a kernel are:</strong></p><ul id="b795bbf0-c592-40f8-8401-93f8031f4906" class="bulleted-list"><li>Your images shrinks everytime you convolve it</li></ul><ul id="514d219a-53d9-4997-a0b5-ff246e41744c" class="bulleted-list"><li>Certain pixels (especially in the middle of the image) become overlapped when convolving, you end up throwing a lot of information from the edges of the image.</li></ul><p id="850b79d3-39a9-45aa-9f34-38cc8c5ebb54" class="">
</p><p id="7ab75eb7-0125-4172-8b3b-f3816dad2c39" class="">Sometimes you don&#x27;t want your input to become smaller, this can be achieved with the &#x27;padding mechanism&#x27;.</p><p id="514fda7b-9b0a-42ca-b964-cb1cfe3fee99" class="">
</p><p id="06c7bf9d-0914-4315-95bc-7e549f14cbba" class=""><strong>How to fix the above issues:</strong></p><ul id="c930cbfc-9954-4e39-a95a-543761cffa82" class="bulleted-list"><li>Pad the image with an <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>∗</mo><mi>p</mi></mrow><annotation encoding="application/x-tex">p*p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6597200000000001em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span></span></span></span></span><span>﻿</span></span> padding around the image such that now you have <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>+</mo><mn>2</mn><mi>p</mi><mo>−</mo><mi>f</mi><mo>+</mo><mn>1</mn><mo>∗</mo><mi>n</mi><mo>+</mo><mn>2</mn><mi>p</mi><mo>−</mo><mi>f</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">n+2p-f+1*n+2p-f+1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="mord">2</span><span class="mord mathdefault">p</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="mord">2</span><span class="mord mathdefault">p</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span></span><span>﻿</span></span> input image, this ensures that after convolving you retain the original size of the image.</li></ul><p id="dee805f6-30c5-42bb-9d4f-35aa3c0f7bea" class="">This method is usually referred to as Zero Padding, when applying zeros around the image.</p><p id="63b80547-9bb1-43f0-a336-04bb077cbe07" class="">
</p><p id="f7f9d8f7-dac7-4c45-b9dc-c4d264af4c12" class="">Useful resource: <a href="https://www.machinecurve.com/index.php/2020/02/07/what-is-padding-in-a-neural-network/">https://www.machinecurve.com/index.php/2020/02/07/what-is-padding-in-a-neural-network/</a></p><p id="1d07fbb7-0657-40e3-ba0d-185a62cc1f99" class="">
</p><p id="52fe531f-f71a-4808-80c7-9f113aa84baf" class=""><strong>How much to pad? There&#x27;s 2 common choices when it comes to padding:</strong></p><figure id="a19115ba-5599-429c-b0fa-fe91f3ba470a" class="image"><a href="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%208.png"><img style="width:805px" src="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%208.png"/></a></figure><p id="49e08bf4-112f-4dc7-a9ea-418efb9f7dd2" class="">Note: It is common in computer vision to use a kernel size odd value.</p><h2 id="acd527b4-2d57-4a6b-96d9-d2ffcad125a6" class="">Strided Convolutions</h2><p id="e9b37f35-2d5c-45ff-8690-6bb64aecd191" class="">Strided convolutions is another piece of the basic building block of convolutions as used in Convolutional Neural Networks. As shown in the  example below. Suppose you want to convolve this <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>7</mn><mo>∗</mo><mn>7</mn></mrow><annotation encoding="application/x-tex">7*7</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">7</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">7</span></span></span></span></span><span>﻿</span></span> image with this <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>∗</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">3*3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span></span><span>﻿</span></span> filter/kernel, except that instead of doing the usual way, we are going to do it with a stride of 2. What that means is you take the element-wise product as usual in this upper left <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>∗</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">3*3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span></span><span>﻿</span></span> region and then multiply and add and that gives you 91. But then instead of stepping the blue box over by one step, we are going to step over by two steps. So, we are going to make it hop over two steps as shown. </p><p id="b293788a-8e8a-4c41-825c-609c6b715147" class="">Notice how the upper left hand corner has gone from this start to this start, jumping over one position. And then you do the usual element Y&#x27;s product and summing it turns out 100. so on...</p><figure id="9033c20e-accb-4b07-98ab-ed6d422232bd" class="image"><a href="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%209.png"><img style="width:794px" src="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%209.png"/></a></figure><p id="79d71223-e8dc-4d7e-b340-89c328ad61c8" class="">Note: If the value of <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span></span></span></span></span><span>﻿</span></span> is a float then you take the floor of that value: <code>np.floor(f)</code></p><p id="02f41d74-5ecb-4a84-8f56-7e3e2771203a" class="">
</p><p id="6f5f102f-cedf-462a-b67b-eba5c819cdef" class="">In summary:</p><figure id="91e380a3-dc68-4957-bab7-cd03bd487438" class="image"><a href="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%2010.png"><img style="width:787px" src="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%2010.png"/></a></figure><h2 id="85b4f6aa-e87f-4996-a600-d0950193c811" class="">Convolutions Over Volume</h2><p id="0161c5f8-28da-4298-9b9f-cbce385f845e" class="">Suppose you want to detect features on an RGB image, in order to detect them you would convolve the image with a 3 channel/depth filter. The number of channels in the image should match the filters channel.</p><p id="27e4cb3b-5bce-4257-be82-bbc8aad8a2dc" class="">The benefit of using a 3 channel filter is that you could filter specific colors of the RGB image, In the example below you could set the kernel to only detect vertical edges only in the Red channel/depth by setting the Green and Blue to zero.</p><figure id="b618b3c1-e36a-4314-9c46-9c9f71bca00b" class="image"><a href="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%2011.png"><img style="width:797px" src="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%2011.png"/></a></figure><p id="0137e66e-8e55-4d00-9f35-608ab241dd94" class="">
</p><p id="7bdc54ec-9969-4da1-8be4-9ae01eb77126" class="">Suppose you want to have multiple filters in an image, you could similarly apply the above but instead now your output will have x channel(s) depending on the number of filters used.</p><figure id="2be0bb61-6eba-4d9d-9e36-eccc4addd647" class="image"><a href="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%2012.png"><img style="width:789px" src="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%2012.png"/></a></figure><h2 id="f452163d-104b-4ae4-8c96-6f2b78877f99" class="">One Layer of a Convolutional Network</h2><p id="def185f4-8db6-469f-a3db-1995eb6a4f12" class="">Similarly, when convoling convnets we follow the same approach as shown above but instead now we treat everything as convnets.</p><figure id="59f32411-bb8b-48ae-9c9a-217a23771b1c" class="image"><a href="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%2013.png"><img style="width:805px" src="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%2013.png"/></a></figure><p id="c83005cb-ca8d-4f38-b0eb-bd6885079450" class="">Summary of notation</p><figure id="ad1e11ae-8e68-4637-8141-0948b5aacf38" class="image"><a href="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%2014.png"><img style="width:795px" src="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%2014.png"/></a></figure><h2 id="14b9da8e-0238-4665-98fc-da73a8ff9b91" class="">Simple Convolutional Network Example</h2><figure id="243dbc2e-359b-4c59-a25d-6861c44a09e8" class="image"><a href="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%2015.png"><img style="width:796px" src="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%2015.png"/></a></figure><p id="eca75a12-a83e-47aa-9980-14c88e1fa08d" class="">Suppose you have an image that you want to do image classification/recognition. Where you take an input image X and decide if image contains a cat or not.</p><p id="d4dde4f0-1405-4fe9-ba60-3a34b85a6a53" class="">You could build a simple ConvNet as shown above. Suppose the image dims are <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>39</mn><mo>∗</mo><mn>39</mn><mo>∗</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">39*39*3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span><span class="mord">9</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span><span class="mord">9</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span></span><span>﻿</span></span> and say we convolve this input image with a 3 layered 1 strided 10 filters with no padding in order to detect features.</p><p id="cdd04971-22a2-4328-bad3-3d62ce643075" class="">The dims of the activations in the next layer of the nn will be <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>37</mn><mo>∗</mo><mn>37</mn><mo>∗</mo><mn>10</mn></mrow><annotation encoding="application/x-tex">37*37*10</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span><span class="mord">7</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span><span class="mord">7</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">0</span></span></span></span></span><span>﻿</span></span>, 10 resulting from the number of filters from the previous kernel used.</p><p id="f6f204fe-ddbc-466c-905d-baba4b7a33e9" class="">Suppose you want to pass it through another filter (<style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><mo>∗</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">5*5 </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">5</span></span></span></span></span><span>﻿</span></span> filter) and maybe with no padding and 20 filters. The output of that will be another volumed nn which will be a <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>17</mn><mo>∗</mo><mn>17</mn><mo>∗</mo><mn>20</mn></mrow><annotation encoding="application/x-tex">17*17*20</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">7</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">7</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">0</span></span></span></span></span><span>﻿</span></span>, due to the use of 2 strides the dimensions shrunk much faster from <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>37</mn><mo>∗</mo><mn>37</mn></mrow><annotation encoding="application/x-tex">37*37</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span><span class="mord">7</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span><span class="mord">7</span></span></span></span></span><span>﻿</span></span> to <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>17</mn><mo>∗</mo><mn>17</mn></mrow><annotation encoding="application/x-tex">17*17</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">7</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">7</span></span></span></span></span><span>﻿</span></span>. </p><p id="d65ab4b1-78bc-429b-a7a4-0b14680e9ca3" class="">If we apply another filter before flattening the results in order to get our softmax probabilities we could end up with a <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>7</mn><mo>∗</mo><mn>7</mn><mo>∗</mo><mn>40</mn></mrow><annotation encoding="application/x-tex">7*7*40</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">7</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">7</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">4</span><span class="mord">0</span></span></span></span></span><span>﻿</span></span> volume with 1960 values. By simply using a <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><mo>∗</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">5*5 </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">5</span></span></span></span></span><span>﻿</span></span> filter a stride of 2 and 40 filters with no padding.</p><p id="f83e3e57-bd6c-4074-ac1a-59bc7284a5e6" class="">This means that we went from an RGB image of <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>37</mn><mo>∗</mo><mn>37</mn><mo>∗</mo><mn>3</mn></mrow><annotation encoding="application/x-tex"> 37*37*3 </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span><span class="mord">7</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span><span class="mord">7</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span></span><span>﻿</span></span> to <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>7</mn><mo>∗</mo><mn>7</mn><mo>∗</mo><mn>40</mn></mrow><annotation encoding="application/x-tex">7*7*40 </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">7</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">7</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">4</span><span class="mord">0</span></span></span></span></span><span>﻿</span></span>features of the images which will be flattened to 1960 units. What&#x27;s left is to feed this units into a logistic regression or softmax unit.</p><p id="5a6554d9-9449-4775-81b6-e00485579520" class="">
</p><p id="bfc22c3e-8450-4f64-a517-4e4c5a8cafe7" class=""><strong>Types of layer in a convolutional network:</strong></p><ul id="89cfe73f-f209-4d3e-9a7f-a1ad91609c67" class="bulleted-list"><li>Convoltion (Conv)</li></ul><ul id="ff7b4a26-7f60-4ab2-b5cd-6ddf385fc037" class="bulleted-list"><li>Pooling (Pool)</li></ul><ul id="5ed99c29-9ab3-4306-bb82-160f8e5d6807" class="bulleted-list"><li>Fully connected (FC)</li></ul><h2 id="f31ade7d-5723-4ecb-a8a3-75450d71c9f7" class="">Pooling Layers</h2><p id="690df156-5536-475b-a6aa-d92f1d8559dc" class="">Other than convolutional layers, ConvNets often also use pooling layers to reduce the size of the representation, to speed the computation, as well as make some of the features that detects a bit more robust</p><figure id="c017291a-a744-4f8e-87bc-e0bc24242e42" class="image"><a href="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%2016.png"><img style="width:793px" src="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%2016.png"/></a></figure><p id="3cf3e4e3-55a7-49d8-8e25-98ddfbe3c6d8" class="">Suppose you have a 4x4 input and want to apply a pooling called max pooling. Max pooling is the process of reducing the size of an input image by simmarizing regions, values are converted into a single value by taking the maximum value from among them.</p><p id="77ed6b70-fb61-4058-a09a-4cb688136ce5" class="">So we would need to take the 4*4 input and break it into different regions, then take the max of each shaded region into its corresponding region on the right (2*2 region).</p><p id="ce12e53f-abe0-4da6-b7b4-0facf1135d84" class="">This is as if you are applying a 2 layer filter with a stride of 2.</p><p id="a9f9081f-4413-4d20-bbdf-0f8d54319182" class="">
</p><p id="0915f44c-b927-43d0-9ec5-25bad07775b6" class="">The intuition behind what&#x27;s maxpooling is doing, if you think of this 4*4 region as some set of features, the activations in some later of the nn. Then a large number, means a particular feature was detected. So that the max operation does is as long as the features is detected anywhere in one of the quadrants, it then remains preserved in the output of max pooling. In short, if these features are detected anywhere in this filter, then keep a high number and if not detected then feature does not exist. </p><p id="fa9e57c1-17cc-4b45-b3bf-9b8449d756ce" class="">
</p><p id="d61c3e26-0f16-4bce-aa5a-c8b7c6e52e65" class="">One interesting property of max pooling is that it has a set of hyperparametes but it has no parameters to learn i.e nothing for gradient descent to learn.</p><p id="5e4df6be-f127-4388-b7f7-3567ada03640" class="">
</p><p id="e424906d-7d1f-4274-86e2-b75ba1c10657" class="">Resource:</p><figure id="10f532d4-093a-4605-92bf-2b8a52304d65"><div class="source"><a href="https://youtu.be/ZjM_XQa5s6s">https://youtu.be/ZjM_XQa5s6s</a></div></figure><p id="c0c63844-ae5c-436e-a33e-de36836eb235" class="">
</p><p id="4c52c5cf-6369-48af-9db0-50679950ff01" class="">Another type of pooling that isn&#x27;t used often is the <strong>Average pooling. </strong>It takes the average of the kernel region.</p><figure id="fab70078-74ce-4fbd-9ff8-1c00bc202c4c" class="image"><a href="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%2017.png"><img style="width:776px" src="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%2017.png"/></a></figure><h2 id="6361acaa-6f18-4598-913c-285a41c2bafd" class="">CNN Example</h2><figure id="70c3f317-bc3e-4521-9a42-6d4155a43ae7" class="image"><a href="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%2018.png"><img style="width:775px" src="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%2018.png"/></a></figure><p id="8401c775-7d2c-47c1-b920-34490fc679ad" class="">Suppose you are building a hand written digit recognizer as illustrated in the image above. The input image being <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>32</mn><mo>∗</mo><mn>32</mn><mo>∗</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">32*32*3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span></span><span>﻿</span></span>, the first layer ises a 5x5 filter and string of 1. Then output becomes 28*28*6 if using 6 filters this would form part of layer 1 conv1, next we apply a maxpool (2 filter, 2 stride) this reduces the outut to 14*14*6 and this forms part of layer 1 pool 1 ...So on and so on until you get a flattened pool2 into a 400 dims vector, then build a fully connected layer of 120 nodes (each of the 400 units connect to each of the 120 units)...</p><p id="dea9ad9e-3f69-493b-95d1-abef6ee5164f" class="">
</p><p id="8150e31d-582d-4fe7-92b1-ed8cb96f9d5f" class="">The pattern above is very common when working with convnets.</p><p id="f0cb406c-e762-407e-9909-9e1b8e2e7011" class="">where: Conv→Pool→Conv→Pool→FC→FC→Softmax</p><p id="2fb82581-a37b-4f22-bd05-c0b54bb44704" class="">
</p><div id="543d880f-a763-45c0-8e3e-8e3525763ae5" class="collection-content"><h4 class="collection-title">Neural network example</h4><table class="collection-content"><thead><tr><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.4);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesTitle"><path d="M7.73943662,8.6971831 C7.77640845,8.7834507 7.81338028,8.8943662 7.81338028,9.00528169 C7.81338028,9.49823944 7.40669014,9.89260563 6.91373239,9.89260563 C6.53169014,9.89260563 6.19894366,9.64612676 6.08802817,9.30105634 L5.75528169,8.33978873 L2.05809859,8.33978873 L1.72535211,9.30105634 C1.61443662,9.64612676 1.2693662,9.89260563 0.887323944,9.89260563 C0.394366197,9.89260563 0,9.49823944 0,9.00528169 C0,8.8943662 0.0246478873,8.7834507 0.0616197183,8.6971831 L2.46478873,2.48591549 C2.68661972,1.90669014 3.24119718,1.5 3.90669014,1.5 C4.55985915,1.5 5.12676056,1.90669014 5.34859155,2.48591549 L7.73943662,8.6971831 Z M2.60035211,6.82394366 L5.21302817,6.82394366 L3.90669014,3.10211268 L2.60035211,6.82394366 Z M11.3996479,3.70598592 C12.7552817,3.70598592 14,4.24823944 14,5.96126761 L14,9.07922535 C14,9.52288732 13.6549296,9.89260563 13.2112676,9.89260563 C12.8169014,9.89260563 12.471831,9.59683099 12.4225352,9.19014085 C12.028169,9.6584507 11.3257042,9.95422535 10.5492958,9.95422535 C9.60035211,9.95422535 8.47887324,9.31338028 8.47887324,7.98239437 C8.47887324,6.58978873 9.60035211,6.08450704 10.5492958,6.08450704 C11.3380282,6.08450704 12.040493,6.33098592 12.4348592,6.81161972 L12.4348592,5.98591549 C12.4348592,5.38204225 11.9172535,4.98767606 11.1285211,4.98767606 C10.6602113,4.98767606 10.2411972,5.11091549 9.80985915,5.38204225 C9.72359155,5.43133803 9.61267606,5.46830986 9.50176056,5.46830986 C9.18133803,5.46830986 8.91021127,5.1971831 8.91021127,4.86443662 C8.91021127,4.64260563 9.0334507,4.44542254 9.19366197,4.34683099 C9.87147887,3.90316901 10.6232394,3.70598592 11.3996479,3.70598592 Z M11.1778169,8.8943662 C11.6830986,8.8943662 12.1760563,8.72183099 12.4348592,8.37676056 L12.4348592,7.63732394 C12.1760563,7.29225352 11.6830986,7.11971831 11.1778169,7.11971831 C10.5616197,7.11971831 10.056338,7.45246479 10.056338,8.0193662 C10.056338,8.57394366 10.5616197,8.8943662 11.1778169,8.8943662 Z M0.65625,11.125 L13.34375,11.125 C13.7061869,11.125 14,11.4188131 14,11.78125 C14,12.1436869 13.7061869,12.4375 13.34375,12.4375 L0.65625,12.4375 C0.293813133,12.4375 4.43857149e-17,12.1436869 0,11.78125 C-4.43857149e-17,11.4188131 0.293813133,11.125 0.65625,11.125 Z"></path></svg></span>Name</th><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.4);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesText"><path d="M7,4.56818 C7,4.29204 6.77614,4.06818 6.5,4.06818 L0.5,4.06818 C0.223858,4.06818 0,4.29204 0,4.56818 L0,5.61364 C0,5.88978 0.223858,6.11364 0.5,6.11364 L6.5,6.11364 C6.77614,6.11364 7,5.88978 7,5.61364 L7,4.56818 Z M0.5,1 C0.223858,1 0,1.223858 0,1.5 L0,2.54545 C0,2.8216 0.223858,3.04545 0.5,3.04545 L12.5,3.04545 C12.7761,3.04545 13,2.8216 13,2.54545 L13,1.5 C13,1.223858 12.7761,1 12.5,1 L0.5,1 Z M0,8.68182 C0,8.95796 0.223858,9.18182 0.5,9.18182 L11.5,9.18182 C11.7761,9.18182 12,8.95796 12,8.68182 L12,7.63636 C12,7.36022 11.7761,7.13636 11.5,7.13636 L0.5,7.13636 C0.223858,7.13636 0,7.36022 0,7.63636 L0,8.68182 Z M0,11.75 C0,12.0261 0.223858,12.25 0.5,12.25 L9.5,12.25 C9.77614,12.25 10,12.0261 10,11.75 L10,10.70455 C10,10.4284 9.77614,10.20455 9.5,10.20455 L0.5,10.20455 C0.223858,10.20455 0,10.4284 0,10.70455 L0,11.75 Z"></path></svg></span>Activation shape</th><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.4);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesText"><path d="M7,4.56818 C7,4.29204 6.77614,4.06818 6.5,4.06818 L0.5,4.06818 C0.223858,4.06818 0,4.29204 0,4.56818 L0,5.61364 C0,5.88978 0.223858,6.11364 0.5,6.11364 L6.5,6.11364 C6.77614,6.11364 7,5.88978 7,5.61364 L7,4.56818 Z M0.5,1 C0.223858,1 0,1.223858 0,1.5 L0,2.54545 C0,2.8216 0.223858,3.04545 0.5,3.04545 L12.5,3.04545 C12.7761,3.04545 13,2.8216 13,2.54545 L13,1.5 C13,1.223858 12.7761,1 12.5,1 L0.5,1 Z M0,8.68182 C0,8.95796 0.223858,9.18182 0.5,9.18182 L11.5,9.18182 C11.7761,9.18182 12,8.95796 12,8.68182 L12,7.63636 C12,7.36022 11.7761,7.13636 11.5,7.13636 L0.5,7.13636 C0.223858,7.13636 0,7.36022 0,7.63636 L0,8.68182 Z M0,11.75 C0,12.0261 0.223858,12.25 0.5,12.25 L9.5,12.25 C9.77614,12.25 10,12.0261 10,11.75 L10,10.70455 C10,10.4284 9.77614,10.20455 9.5,10.20455 L0.5,10.20455 C0.223858,10.20455 0,10.4284 0,10.70455 L0,11.75 Z"></path></svg></span>Activation Size</th><th><span class="icon property-icon"><svg viewBox="0 0 14 14" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.4);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesText"><path d="M7,4.56818 C7,4.29204 6.77614,4.06818 6.5,4.06818 L0.5,4.06818 C0.223858,4.06818 0,4.29204 0,4.56818 L0,5.61364 C0,5.88978 0.223858,6.11364 0.5,6.11364 L6.5,6.11364 C6.77614,6.11364 7,5.88978 7,5.61364 L7,4.56818 Z M0.5,1 C0.223858,1 0,1.223858 0,1.5 L0,2.54545 C0,2.8216 0.223858,3.04545 0.5,3.04545 L12.5,3.04545 C12.7761,3.04545 13,2.8216 13,2.54545 L13,1.5 C13,1.223858 12.7761,1 12.5,1 L0.5,1 Z M0,8.68182 C0,8.95796 0.223858,9.18182 0.5,9.18182 L11.5,9.18182 C11.7761,9.18182 12,8.95796 12,8.68182 L12,7.63636 C12,7.36022 11.7761,7.13636 11.5,7.13636 L0.5,7.13636 C0.223858,7.13636 0,7.36022 0,7.63636 L0,8.68182 Z M0,11.75 C0,12.0261 0.223858,12.25 0.5,12.25 L9.5,12.25 C9.77614,12.25 10,12.0261 10,11.75 L10,10.70455 C10,10.4284 9.77614,10.20455 9.5,10.20455 L0.5,10.20455 C0.223858,10.20455 0,10.4284 0,10.70455 L0,11.75 Z"></path></svg></span># Parameters</th></tr></thead><tbody><tr id="79049d3f-c10b-4ca3-8fe0-b3b2fc920130"><td class="cell-title"><a href="Week%201%20d6239cbce5d84a098095562a3f8340ab/Neural%20network%20example%20543d880fa76345c08e3e8e3525763ae5/Input%2079049d3fc10b4ca38fe0b3b2fc920130.html">Input</a></td><td class="cell-w[Jj">(32,32,3)</td><td class="cell-U[~a">3072</td><td class="cell-lAux">0</td></tr><tr id="87c00082-66d5-4a2c-96a9-9d53ed1b03be"><td class="cell-title"><a href="Week%201%20d6239cbce5d84a098095562a3f8340ab/Neural%20network%20example%20543d880fa76345c08e3e8e3525763ae5/CONV1%20(f=5,%20s=1)%2087c0008266d54a2c96a99d53ed1b03be.html">CONV1 (f=5, s=1)</a></td><td class="cell-w[Jj">(28,28,8)</td><td class="cell-U[~a">6272</td><td class="cell-lAux">608</td></tr><tr id="0f825bc5-6f8e-4799-990d-7974578b4f3a"><td class="cell-title"><a href="Week%201%20d6239cbce5d84a098095562a3f8340ab/Neural%20network%20example%20543d880fa76345c08e3e8e3525763ae5/POOL1%200f825bc56f8e4799990d7974578b4f3a.html">POOL1</a></td><td class="cell-w[Jj">(14,14,8)</td><td class="cell-U[~a">1568</td><td class="cell-lAux">0</td></tr><tr id="b14cfed0-b07b-4aba-859b-045f4ff08b0b"><td class="cell-title"><a href="Week%201%20d6239cbce5d84a098095562a3f8340ab/Neural%20network%20example%20543d880fa76345c08e3e8e3525763ae5/CONV2(f=5,s=1)%20b14cfed0b07b4aba859b045f4ff08b0b.html">CONV2(f=5,s=1)</a></td><td class="cell-w[Jj">(10,10,16)</td><td class="cell-U[~a">1600</td><td class="cell-lAux">3216</td></tr><tr id="94db0f89-0457-46ed-99d2-2f8ba45f40d9"><td class="cell-title"><a href="Week%201%20d6239cbce5d84a098095562a3f8340ab/Neural%20network%20example%20543d880fa76345c08e3e8e3525763ae5/POOL2%2094db0f89045746ed99d22f8ba45f40d9.html">POOL2</a></td><td class="cell-w[Jj">(5,5,16)</td><td class="cell-U[~a">400</td><td class="cell-lAux">0</td></tr><tr id="480d3b3b-22f9-45fc-82ca-a0bbc26e41c7"><td class="cell-title"><a href="Week%201%20d6239cbce5d84a098095562a3f8340ab/Neural%20network%20example%20543d880fa76345c08e3e8e3525763ae5/FC3%20480d3b3b22f945fc82caa0bbc26e41c7.html">FC3</a></td><td class="cell-w[Jj">(120,1)</td><td class="cell-U[~a">120</td><td class="cell-lAux">48120</td></tr><tr id="c20c7f3e-759e-415e-b598-e0e879d0a908"><td class="cell-title"><a href="Week%201%20d6239cbce5d84a098095562a3f8340ab/Neural%20network%20example%20543d880fa76345c08e3e8e3525763ae5/FC4%20c20c7f3e759e415eb598e0e879d0a908.html">FC4</a></td><td class="cell-w[Jj">(84,1)</td><td class="cell-U[~a">84</td><td class="cell-lAux">10164</td></tr><tr id="0aad058f-9e5a-42b0-ba0c-3fad7dc4730f"><td class="cell-title"><a href="Week%201%20d6239cbce5d84a098095562a3f8340ab/Neural%20network%20example%20543d880fa76345c08e3e8e3525763ae5/Softmax%200aad058f9e5a42b0ba0c3fad7dc4730f.html">Softmax</a></td><td class="cell-w[Jj">(10,1)</td><td class="cell-U[~a">10</td><td class="cell-lAux">850</td></tr></tbody></table></div><p id="033fc3b4-568b-48f9-90bf-40cf1965aa76" class="">In summary, what we see is that the activation size gradually descreases and the pooling layers never have any parameters. Notice that conv later tend to have few parameters. Infact a lot of the parameters tend to be in the fully connected layer of the nn. If the activation size drops too quickly thats usually not great for perfomance.</p><h2 id="37372dcd-ba7f-4258-986e-838ddf9ed787" class="">Why Convolutions?</h2><p id="4a8a6a74-70b3-4ccd-a0d0-5a0266f10431" class="">Why not use fully connected layers, one of the main reason is that if we flatten the input and connect all the neurons to the following layer this would be a lot of parameters to train. The higher the image dimensions the higher the features to train.</p><figure id="9c623ec0-cbc1-46f1-9192-fc4e070f2f07" class="image"><a href="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%2019.png"><img style="width:674px" src="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%2019.png"/></a></figure><p id="c56d77d0-f831-4dd0-be14-1bc13eff8536" class="">There&#x27;s 2 main advantages of using convnets over fully connected layers:</p><ul id="ffc7cfea-7f4c-42e7-93de-168711e3d820" class="bulleted-list"><li>Parameter sharing: A feature detector (such as a vertical edge detector) that&#x27;s useful in one part of the image is probably useful in another part of the image.</li></ul><ul id="d0b08e3a-8253-4799-96ea-67c909aeec47" class="bulleted-list"><li>Sparsity of connections: In each layer, each output value depends only on a small number of inputs.</li></ul><p id="0f9920db-a58a-4386-b55d-d319e4193182" class="">
</p><p id="dbd52fbb-ef99-47e1-aaec-0cdf1e9df17b" class="">Putting it all together, suppose you want to create a cat detector as shown in the image below</p><figure id="c5363f74-448e-41d4-802d-0108580fab01" class="image"><a href="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%2020.png"><img style="width:782px" src="Week%201%20d6239cbce5d84a098095562a3f8340ab/Untitled%2020.png"/></a></figure><p id="c56d4ec8-09c1-4421-a774-62e68c1b6a82" class="">where now, X is an image. And the y&#x27;s can be binary labels, or one of K classes. And let&#x27;s say you&#x27;ve chosen a convolutional neural network structure, may be inserted the image and then having neural convolutional and pooling layers and then some fully connected layers followed by a softmax output that then operates <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Y</mi><mrow><mi>h</mi><mi>a</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Y_{hat}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>. The conv layers and the fully connected layers will have various parameters, W, as well as bias&#x27;s B. And so, any setting of the parameters, therefore, lets you define a cost function similar to what we have seen in the previous courses, where we&#x27;ve randomly initialized parameters W and B. You can compute the cause J, as the sum of losses of the neural networks predictions on your entire training set, maybe divide it by M. So, to train this neural network, all you need to do is then use gradient descents or some of the algorithm like, gradient descent momentum, or RMSProp or Adam, or something else, in order to optimize all the parameters of the neural network to try to reduce the cost function J.</p><p id="cc1f3b7a-af8b-4541-85d4-0f0f779fe40e" class="">
</p><p id="dca60dd8-bae7-4c3a-9062-7ce14a6a10b8" class="">
</p><p id="43d535e7-1626-45db-8f6f-6d6731076eaf" class="">Resource: </p><figure id="1873b373-782b-4a12-9827-e9868de85c94"><a href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">A Comprehensive Guide to Convolutional Neural Networks - the ELI5 way</div><div class="bookmark-description">Artificial Intelligence has been witnessing a monumental growth in bridging the gap between the capabilities of humans and machines. Researchers and enthusiasts alike, work on numerous aspects of the field to make amazing things happen. One of many such areas is the domain of Computer Vision.</div></div><div class="bookmark-href"><img src="https://miro.medium.com/fit/c/256/256/1*ChFMdf--f5jbm-AYv6VdYA@2x.png" class="icon bookmark-icon"/>https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53</div></div><img src="https://miro.medium.com/max/1200/1*vkQ0hXDaQv57sALXAJquxA.jpeg" class="bookmark-image"/></a></figure><hr id="661567d2-ca23-4eb7-9849-07ca98ac7cde"/><h1 id="87e77700-e1f7-495c-8c68-b5afa32a200c" class="">Q &amp; A</h1><h2 id="03840dfa-d05a-4f89-a137-5b060dc7107c" class="">The basics of ConvNets</h2><p id="4f68cfee-a750-4e84-a252-0e09f88822df" class="">
</p><ol id="7a1c4eb7-150d-4e27-858b-5a2aac5d2e02" class="numbered-list" start="1"><li>What do you think applying this filter to a grayscale image will do?<p id="b01c3128-dd90-4fe9-af07-6f89a924c9e2" class="">0 1 -1 0
1 3 -3 -1
1 3 -3 -1
0 1 -1 0</p><ul id="32a9083a-d00a-4201-9523-2363bbdfe1ac" class="bulleted-list"><li>Detect Vertical edges</li></ul></li></ol><ol id="4de20d92-25fc-43af-adc5-7061750294e9" class="numbered-list" start="2"><li>Suppose your input is a 300 by 300 color (RGB) image, and you are not using a convolutional network. If the first hidden layer has 100 neurons, each one fully connected to the input, how many parameters does this hidden layer have (including the bias parameters)?<ul id="bf17079d-a516-4f91-9007-d38f567a01ab" class="bulleted-list"><li>27,000,100</li></ul></li></ol><ol id="59ade58b-2129-478f-9a19-fe6dab726cc1" class="numbered-list" start="3"><li>Suppose your input is a 300 by 300 color (RGB) image, and you use a convolutional layer with 100 filters that are each 5x5. How many parameters does this hidden layer have (including the bias parameters)?<ul id="c341b01d-0f0e-4cb2-9af6-654ed5d777ac" class="bulleted-list"><li>2600</li></ul></li></ol><ol id="39e93304-52ae-4084-b7b1-26448a99e56e" class="numbered-list" start="4"><li>You have an input volume that is 63x63x16, and convolve it with 32 filters that are each 7x7, using a stride of 2 and no padding. What is the output volume?<ul id="36f47856-c68a-4afc-90a4-712326fc603c" class="bulleted-list"><li>29x29x32</li></ul></li></ol><ol id="a930f04d-619b-4473-bc10-761cdf6a24ae" class="numbered-list" start="5"><li>You have an input volume that is 15x15x8, and pad it using “pad=2.” What is the dimension of the resulting volume (after padding)?<ul id="7bc41eff-8458-4a1b-8b01-29acde83c5e1" class="bulleted-list"><li>19x19x8</li></ul></li></ol><ol id="1c7605c5-dd4e-457f-96ae-7d549dc09346" class="numbered-list" start="6"><li>You have an input volume that is 63x63x16, and convolve it with 32 filters that are each 7x7, and stride of 1. You want to use a “same” convolution. What is the padding?<ul id="3387abfe-21a0-42d6-8304-46edceca797d" class="bulleted-list"><li>3 </li></ul></li></ol><ol id="4195e7f0-9e94-45e0-a34c-a8d4f8ef3a6b" class="numbered-list" start="7"><li>You have an input volume that is 32x32x16, and apply max pooling with a stride of 2 and a filter size of 2. What is the output volume?<ul id="bbff7832-1ad6-4a43-ae63-ba3a9f1dc5a5" class="bulleted-list"><li>16x16x16</li></ul></li></ol><ol id="31e99f83-5302-422e-8ce9-7f7f4ffe009d" class="numbered-list" start="8"><li>Because pooling layers do not have parameters, they do not affect the backpropagation (derivatives) calculation.<ul id="11ba68df-5a35-474a-b68c-2eb72797464e" class="bulleted-list"><li>False</li></ul></li></ol><ol id="763d029e-31b9-4a1f-bde0-e73763f551f5" class="numbered-list" start="9"><li>In lecture we talked about “parameter sharing” as a benefit of using convolutional networks. Which of the following statements about parameter sharing in ConvNets are true? (Check all that apply.)<ul id="a496a2a4-3a17-47fa-93c4-80eda92f58e7" class="bulleted-list"><li>It reduces the total number of parameters, thus reducing overfitting.</li></ul><ul id="2067adf4-d826-4765-a93b-86b34eed9da5" class="bulleted-list"><li>It allows a feature detector to be used in multiple locations throughout the whole input image/input volume.</li></ul></li></ol><ol id="5f956a6d-9137-4700-9382-9b387d16b9db" class="numbered-list" start="10"><li>In lecture we talked about “sparsity of connections” as a benefit of using convolutional layers. What does this mean?<ul id="d1560923-2d75-4e25-a8ae-2a90b3c7b4f9" class="bulleted-list"><li>Each activation in the next layer depends on only a small number of activations from the previous layer.</li></ul></li></ol></div></article></body></html>